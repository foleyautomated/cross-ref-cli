# Embedding Model Configuration
# The HuggingFace model identifier for generating embeddings
EMBEDDING_MODEL=BAAI/bge-base-en-v1.5

# Text Chunking Configuration
# Size of each text chunk in characters
CHUNK_SIZE=512

# Number of characters to overlap between consecutive chunks
# This helps maintain context across chunk boundaries
CHUNK_OVERLAP=50

# Processing Configuration
# Number of chunks to process in a single batch
BATCH_SIZE=32

# Maximum token length for the embedding model
MAX_TOKENS=512

# Device Configuration
# Options: 'cpu', 'cuda', 'mps' (for Apple Silicon)
DEVICE=cpu

# Embedding Options
# Whether to normalize embeddings to unit length (recommended for cosine similarity)
NORMALIZE_EMBEDDINGS=true

# Comparison Configuration
# Minimum similarity score threshold (0.0 to 1.0) for reporting matches
SIMILARITY_THRESHOLD=0.7

# Number of top matches to return per query chunk
TOP_K=5

# FAISS Index Configuration
# FAISS index type: 'Flat' for exact search, 'IVF' for approximate search
INDEX_TYPE=Flat

# Number of clusters for IVF index (only used if INDEX_TYPE=IVF)
N_CLUSTERS=100

# Output Configuration
# Whether to include chunk text in CSV output
INCLUDE_CHUNK_TEXT=true

# Maximum characters to display per chunk in output
MAX_CHUNK_DISPLAY=200
